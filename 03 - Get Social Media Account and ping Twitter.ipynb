{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook description\n",
    "\n",
    "In this notebook I first parsed out the social media account fetched from scraping the homepages of the clients' urls. Then used the collected twitter handles to check the twitter accounts and get last tweet, to add more words to text for the nlp piece I will do later. AND to get more info about the \"freshness\" of the company info.\n",
    "\n",
    "One of the things the startup I working with was interested about was to know whether the info provided to them by the clients was still accurate. By checking urls and twitter, we could check whether the url still works and when the last twit was posted. That could give an idea of whether the info about the client is still accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the pickled df with the urls to look for twitter handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./FINAL_pickle_soup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get twitter and other social media links from the homepage scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeautifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b44663b61d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfacebook_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     facebook_links.append([elem['href'] for elem in BeautifulSoup(df['soup'][i],\n\u001b[0m\u001b[1;32m      4\u001b[0m                 'lxml').find_all('a') if 'href' in elem.attrs and \"facebook\" in elem['href']])\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'facebook'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfacebook_links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BeautifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "facebook_links = []\n",
    "for i in df.index:\n",
    "    facebook_links.append([elem['href'] for elem in BeautifulSoup(df['soup'][i],\n",
    "                'lxml').find_all('a') if 'href' in elem.attrs and \"facebook\" in elem['href']])\n",
    "df['facebook'] = facebook_links    \n",
    "\n",
    "print(\"No facebook found {}\".format (len(df.loc[np.array(list(map(len,df.facebook.values)))==0])))\n",
    "print (\"1 facebook found {}\".format (len(df.loc[np.array(list(map(len,df.facebook.values)))==1])))\n",
    "print (\"More than 1 facebook found {}\".format (len(df.loc[np.array(list(map(len,df.facebook.values)))>1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_links = []\n",
    "for i in df.index:\n",
    "    twitter_links.append([elem['href'] for elem in BeautifulSoup(df['soup'][i],\n",
    "                'lxml').find_all('a') if 'href' in elem.attrs and \"twitter\" in elem['href']])\n",
    "df['twitter'] = twitter_links\n",
    "\n",
    "print(\"No twitter links found {}\".format (len(df.loc[np.array(list(map(len,df.twitter.values)))==0])))\n",
    "print (\"One twitter link found {}\".format (len(df.loc[np.array(list(map(len,df.twitter.values)))==1])))\n",
    "print (\"More than 1 twitter links found {}\".format (len(df.loc[np.array(list(map(len,df.twitter.values)))>1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_links = []\n",
    "for i in df.index:\n",
    "    youtube_links.append([elem['href'] for elem in BeautifulSoup(df['soup'][i],\n",
    "                'lxml').find_all('a') if 'href' in elem.attrs and \"youtu\" in elem['href']])\n",
    "df['youtube'] = youtube_links\n",
    "\n",
    "print(\"No youtube links found {}\".format (len(df.loc[np.array(list(map(len,df.youtube.values)))==0])))\n",
    "print (\"One youtube link found {}\".format (len(df.loc[np.array(list(map(len,df.youtube.values)))==1])))\n",
    "print (\"More than 1 youtube link found {}\".format (len(df.loc[np.array(list(map(len,df.youtube.values)))>1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_links = []\n",
    "for i in df.index:\n",
    "    instagram_links.append([elem['href'] for elem in BeautifulSoup(df['soup'][i],\n",
    "                'lxml').find_all('a') if 'href' in elem.attrs and \"instagram\" in elem['href']])\n",
    "df['instagram'] = instagram_links\n",
    "\n",
    "print(\"No instagram links found {}\".format (len(df.loc[np.array(list(map(len,df.instagram.values)))==0])))\n",
    "print (\"One instagram link found {}\".format (len(df.loc[np.array(list(map(len,df.instagram.values)))==1])))\n",
    "print (\"More than 1 instagram link found {}\".format (len(df.loc[np.array(list(map(len,df.instagram.values)))>1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'instagram'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d9322acb17ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'homepage_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No text found {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstagram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Some text found {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstagram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'instagram'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "text = []\n",
    "for i in df.index:\n",
    "    text.append(BeautifulSoup(df['soup'][i],'lxml').text.replace(\"\\n\", \"\"))\n",
    "\n",
    "df['homepage_text'] = text\n",
    "\n",
    "print(\"No text found {}\".format (len(df.loc[np.array(list(map(len,df.instagram.values)))==0])))\n",
    "print (\"Some text found {}\".format (len(df.loc[np.array(list(map(len,df.instagram.values)))>=1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get the timestamp and text of the last tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I used selenium\n",
    "driver = webdriver.Chrome(executable_path=\"../chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the pinned one comes up first, then the first one on the page. Total of 19. Iam only keeping the 1st one.\n",
    "#opens a new browser window for each handle in the list \n",
    "#takes about 5 sec per handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REWRITE THIS FOR SCALE\n",
    "# THROW ON AWS\n",
    "\n",
    "dates = []\n",
    "tweet = []\n",
    "driver = webdriver.Chrome(executable_path=\"../chromedriver\")\n",
    "for i in (twitters):\n",
    "    driver.get(i)\n",
    "    dates.append([element.get_attribute('title') for element in driver.find_elements_by_xpath('//a[starts-with(@class, \"tweet-timestamp js-permalink js-nav js-tooltip\")]')])\n",
    "    tweet.append(driver.find_element_by_class_name('tweet').text)   \n",
    "    sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
